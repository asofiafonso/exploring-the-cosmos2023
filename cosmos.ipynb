{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b6acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from astropy.table import Table\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import time\n",
    "import lightgbm\n",
    "import catboost\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "    \n",
    "#Load data:\n",
    "cat = Table.read('./cosmos2020cat/galaxies_flag.fits', format='fits', hdu=1)\n",
    "data = cat.to_pandas()\n",
    "data = data.dropna()\n",
    "\n",
    "total_time = (time.time() - start)\n",
    "print(f'Total needed time for loading data: {total_time/60} minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98756dd4",
   "metadata": {},
   "source": [
    "# Redshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390d6fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group columns into features (x) and labels (y), with their errors:\n",
    "y = data[['lp_zBEST', 'lp_age', 'lp_dust', 'lp_mass_best', 'lp_SFR_best']].copy()\n",
    "x = data[['HSC_g_FLUX_APER3', 'HSC_r_FLUX_APER3', 'HSC_i_FLUX_APER3',\n",
    "                 'HSC_z_FLUX_APER3', 'HSC_y_FLUX_APER3', 'UVISTA_Y_FLUX_APER3',\n",
    "                 'UVISTA_J_FLUX_APER3', 'UVISTA_H_FLUX_APER3', 'UVISTA_Ks_FLUX_APER3',\n",
    "                 'SC_IB427_FLUX_APER3', 'SC_IB464_FLUX_APER3', 'SC_IA484_FLUX_APER3',\n",
    "                 'SC_IB505_FLUX_APER3', 'SC_IA527_FLUX_APER3', 'SC_IB574_FLUX_APER3', \n",
    "                 'SC_IA624_FLUX_APER3', 'SC_IA679_FLUX_APER3', 'SC_IB709_FLUX_APER3', \n",
    "                 'SC_IA738_FLUX_APER3', 'SC_IA767_FLUX_APER3', 'SC_IB827_FLUX_APER3', \n",
    "                 'SC_NB711_FLUX_APER3', 'SC_NB816_FLUX_APER3', 'UVISTA_NB118_FLUX_APER3', \n",
    "                 'SC_B_FLUX_APER3', 'SC_gp_FLUX_APER3', 'SC_V_FLUX_APER3', 'SC_rp_FLUX_APER3', \n",
    "                 'SC_ip_FLUX_APER3', 'SC_zp_FLUX_APER3', 'SC_zpp_FLUX_APER3', 'HSC_g_FLUXERR_APER3', 'HSC_r_FLUXERR_APER3', 'HSC_i_FLUXERR_APER3',\n",
    "                 'HSC_z_FLUXERR_APER3', 'HSC_y_FLUXERR_APER3', 'UVISTA_Y_FLUXERR_APER3',\n",
    "                 'UVISTA_J_FLUXERR_APER3', 'UVISTA_H_FLUXERR_APER3', 'UVISTA_Ks_FLUXERR_APER3',\n",
    "                 'SC_IB427_FLUXERR_APER3', 'SC_IB464_FLUXERR_APER3', 'SC_IA484_FLUXERR_APER3',\n",
    "                 'SC_IB505_FLUXERR_APER3', 'SC_IA527_FLUXERR_APER3', 'SC_IB574_FLUXERR_APER3', \n",
    "                 'SC_IA624_FLUXERR_APER3', 'SC_IA679_FLUXERR_APER3', 'SC_IB709_FLUXERR_APER3', \n",
    "                 'SC_IA738_FLUXERR_APER3', 'SC_IA767_FLUXERR_APER3', 'SC_IB827_FLUXERR_APER3', \n",
    "                 'SC_NB711_FLUXERR_APER3', 'SC_NB816_FLUXERR_APER3', 'UVISTA_NB118_FLUXERR_APER3', \n",
    "                 'SC_B_FLUXERR_APER3', 'SC_gp_FLUXERR_APER3', 'SC_V_FLUXERR_APER3', 'SC_rp_FLUXERR_APER3', \n",
    "                 'SC_ip_FLUXERR_APER3', 'SC_zp_FLUXERR_APER3', 'SC_zpp_FLUXERR_APER3']].copy()\n",
    "x_err = data[['HSC_g_FLUXERR_APER3', 'HSC_r_FLUXERR_APER3', 'HSC_i_FLUXERR_APER3',\n",
    "                 'HSC_z_FLUXERR_APER3', 'HSC_y_FLUXERR_APER3', 'UVISTA_Y_FLUXERR_APER3',\n",
    "                 'UVISTA_J_FLUXERR_APER3', 'UVISTA_H_FLUXERR_APER3', 'UVISTA_Ks_FLUXERR_APER3',\n",
    "                 'SC_IB427_FLUXERR_APER3', 'SC_IB464_FLUXERR_APER3', 'SC_IA484_FLUXERR_APER3',\n",
    "                 'SC_IB505_FLUXERR_APER3', 'SC_IA527_FLUXERR_APER3', 'SC_IB574_FLUXERR_APER3', \n",
    "                 'SC_IA624_FLUXERR_APER3', 'SC_IA679_FLUXERR_APER3', 'SC_IB709_FLUXERR_APER3', \n",
    "                 'SC_IA738_FLUXERR_APER3', 'SC_IA767_FLUXERR_APER3', 'SC_IB827_FLUXERR_APER3', \n",
    "                 'SC_NB711_FLUXERR_APER3', 'SC_NB816_FLUXERR_APER3', 'UVISTA_NB118_FLUXERR_APER3', \n",
    "                 'SC_B_FLUXERR_APER3', 'SC_gp_FLUXERR_APER3', 'SC_V_FLUXERR_APER3', 'SC_rp_FLUXERR_APER3', \n",
    "                 'SC_ip_FLUXERR_APER3', 'SC_zp_FLUXERR_APER3', 'SC_zpp_FLUXERR_APER3']].copy()\n",
    "\n",
    "#Train validation test split:\n",
    "x_train, x_testval, y_train, y_testval, x_err_train, x_err_testval = train_test_split(x, y, x_err, test_size=0.3, shuffle = True)\n",
    "x_test, x_val, y_test, y_val , x_err_test, x_err_val = train_test_split(x_testval, y_testval, x_err_testval, test_size=0.5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae563f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['lp_zBEST'] + 1 # Only redshifts for now, but 1+z.\n",
    "y_val = y_val['lp_zBEST'] + 1\n",
    "y_test = y_test['lp_zBEST'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3785b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "def metric_scores_rgr(x,y):\n",
    "    \"\"\"Computes the NMAD, bias, outlier fraction for the regression tasks\n",
    "    x: ground-truth data\n",
    "    y: predicted data\n",
    "    \"\"\"\n",
    "    met = np.abs(pd.Series(y-x))\n",
    "    f_out = met/(1+x.astype(np.float32))\n",
    "    nmad=1.48*np.median(f_out)\n",
    "    bias = np.median(f_out)\n",
    "    y_outlier = pd.Series(np.where(f_out > 0.15, 'outlier', 'not outlier'))\n",
    "    r2 = sklearn.metrics.r2_score(x, y)\n",
    "    #print(\"Outliers: \\n\", y_outlier.value_counts())\n",
    "    outlier_fraction = y_outlier.value_counts()['outlier'] / len(y_outlier)\n",
    "    #print(\"Outlier fraction: \\n\", outlier_fraction)\n",
    "    #print(\"\\n Bias: \\n\", bias)\n",
    "    #print(\"\\n NMAD score: \\n\", nmad)\n",
    "    #print('\\n R2 Test: \\n', r2)\n",
    "    return outlier_fraction, nmad, bias, r2\n",
    "\n",
    "metrics = {'n_estimators': [], 'max_depth': [], 'outlier_fraction': [], 'NMAD': [], 'bias': [], 'r2': []}\n",
    "metrics = pd.DataFrame(data=metrics)\n",
    "for i in [50, 100, 150]:\n",
    "    for j in [0, 4, 7, 9]:\n",
    "        metrics['n_estimators']\n",
    "        model = catboost.CatBoostRegressor(n_estimators = i, max_depth = j, verbose = 0)\n",
    "        model.fit(x_train, y_train) # sample_weight = x_err_train\n",
    "        pred_z = model.predict(x_val)\n",
    "        # Tests for metric tuning:\n",
    "        outlier_fraction, nmad, bias, r2 = metric_scores_rgr(y_val, pred_z)\n",
    "        new_row = pd.DataFrame([[i, j, outlier_fraction, nmad, bias, r2]], columns=['n_estimators', 'max_depth', 'outlier_fraction', 'NMAD', 'bias', 'r2'])\n",
    "        metrics = pd.concat([metrics, new_row], axis = 0)\n",
    "        \n",
    "print(metrics)\n",
    "\n",
    "total_time = (time.time() - start)\n",
    "print(f'Total needed time for catboost: {total_time/60} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2443a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:\n",
    "\n",
    "model = catboost.CatBoostRegressor(n_estimators = 150, max_depth = 9, verbose = 0)\n",
    "model.fit(x_train, y_train) # sample_weight = x_err_train\n",
    "pred_z = model.predict(x_test)\n",
    "#Metrics:\n",
    "outlier_fraction, nmad, bias, r2 = metric_scores_rgr(y_test, pred_z)\n",
    "print(\"Outlier fraction: \\n\", outlier_fraction)\n",
    "print(\"\\n Bias: \\n\", bias)\n",
    "print(\"\\n NMAD score: \\n\", nmad)\n",
    "print('\\n R2 Test: \\n', r2)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(y_test-1, pred_z-1)\n",
    "plt.title('Predicted vs. reference redshifts for test dataset')\n",
    "plt.xlabel('data redshift lp_zBEST')\n",
    "plt.ylabel('predicted redshift $z_{pred}$')\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0,10)\n",
    "x0, x1 = 0, 10\n",
    "y0, y1 = 0, 10\n",
    "plt.plot([np.min(y_test-1)-0.3*(1+np.min(y_test-1)), np.max(y_test-1)-0.30*(np.max(y_test-1)+1)], [y0, y1], color = 'red', linewidth = 2, linestyle = 'dashed')\n",
    "plt.plot([np.min(y_test-1)+0.3*(1+np.min(y_test-1)), np.max(y_test-1)+0.30*(np.max(y_test-1)+1)], [y0, y1], color = 'red', linewidth = 2, linestyle = 'dashed')\n",
    "plt.plot([x0, x1], [y0, y1], color = 'black', linewidth = 2)\n",
    "\n",
    "\n",
    "# Histogram:\n",
    "fig_hist = plt.figure(figsize=(7,5))\n",
    "plt.hist(pred_z-1, 20, range = (0,10),facecolor='orange', edgecolor = 'black', alpha=0.5, label = 'predicted redshifts')\n",
    "plt.hist(y_test-1, 20, range = (0,10), facecolor='blue', edgecolor = 'black', alpha=0.5, label = 'catalog redshifts')\n",
    "plt.xlabel('redshift z')\n",
    "plt.legend()\n",
    "# Residuals:\n",
    "residuals = y_test - pred_z\n",
    "fig_res = plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_test-1, residuals, alpha = 0.5, edgecolor = 'black')\n",
    "plt.xlabel('catalog redshift lp_zBEST')\n",
    "plt.ylabel('residuals (lp_zBEST - pred_z)')\n",
    "x0, x1 = 0, 10\n",
    "y0, y1 = 0, 0\n",
    "plt.plot([x0, x1], [y0, y1], color = 'black', linewidth = 2, linestyle = 'dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3692e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance:\n",
    "def plot_feature_importance(importance,names,model_type):\n",
    "    \"\"\"Plots feature importance\n",
    "    importance: features importance output from model\n",
    "    names: features names\n",
    "    model_type: name of the model used to compute features importance\n",
    "    \"\"\"\n",
    "\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False, inplace=True)\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(20,20))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title(model_type + ' Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Names')\n",
    "\n",
    "features_importances = model.feature_importances_ #replace model by your model\n",
    "names = np.array(['HSC_g_FLUX_APER3', 'HSC_r_FLUX_APER3', 'HSC_i_FLUX_APER3',\n",
    "                 'HSC_z_FLUX_APER3', 'HSC_y_FLUX_APER3', 'UVISTA_Y_FLUX_APER3',\n",
    "                 'UVISTA_J_FLUX_APER3', 'UVISTA_H_FLUX_APER3', 'UVISTA_Ks_FLUX_APER3',\n",
    "                 'SC_IB427_FLUX_APER3', 'SC_IB464_FLUX_APER3', 'SC_IA484_FLUX_APER3',\n",
    "                 'SC_IB505_FLUX_APER3', 'SC_IA527_FLUX_APER3', 'SC_IB574_FLUX_APER3', \n",
    "                 'SC_IA624_FLUX_APER3', 'SC_IA679_FLUX_APER3', 'SC_IB709_FLUX_APER3', \n",
    "                 'SC_IA738_FLUX_APER3', 'SC_IA767_FLUX_APER3', 'SC_IB827_FLUX_APER3', \n",
    "                 'SC_NB711_FLUX_APER3', 'SC_NB816_FLUX_APER3', 'UVISTA_NB118_FLUX_APER3', \n",
    "                 'SC_B_FLUX_APER3', 'SC_gp_FLUX_APER3', 'SC_V_FLUX_APER3', 'SC_rp_FLUX_APER3', \n",
    "                 'SC_ip_FLUX_APER3', 'SC_zp_FLUX_APER3', 'SC_zpp_FLUX_APER3', 'HSC_g_FLUXERR_APER3', 'HSC_r_FLUXERR_APER3', 'HSC_i_FLUXERR_APER3',\n",
    "                 'HSC_z_FLUXERR_APER3', 'HSC_y_FLUXERR_APER3', 'UVISTA_Y_FLUXERR_APER3',\n",
    "                 'UVISTA_J_FLUXERR_APER3', 'UVISTA_H_FLUXERR_APER3', 'UVISTA_Ks_FLUXERR_APER3',\n",
    "                 'SC_IB427_FLUXERR_APER3', 'SC_IB464_FLUXERR_APER3', 'SC_IA484_FLUXERR_APER3',\n",
    "                 'SC_IB505_FLUXERR_APER3', 'SC_IA527_FLUXERR_APER3', 'SC_IB574_FLUXERR_APER3', \n",
    "                 'SC_IA624_FLUXERR_APER3', 'SC_IA679_FLUXERR_APER3', 'SC_IB709_FLUXERR_APER3', \n",
    "                 'SC_IA738_FLUXERR_APER3', 'SC_IA767_FLUXERR_APER3', 'SC_IB827_FLUXERR_APER3', \n",
    "                 'SC_NB711_FLUXERR_APER3', 'SC_NB816_FLUXERR_APER3', 'UVISTA_NB118_FLUXERR_APER3', \n",
    "                 'SC_B_FLUXERR_APER3', 'SC_gp_FLUXERR_APER3', 'SC_V_FLUXERR_APER3', 'SC_rp_FLUXERR_APER3', \n",
    "                 'SC_ip_FLUXERR_APER3', 'SC_zp_FLUXERR_APER3', 'SC_zpp_FLUXERR_APER3'])#list of the columns from the X_train data set\n",
    "model_type = 'CatBoost' # change according to the model to be used. Only used in the plots.\n",
    "\n",
    "plot_feature_importance(features_importances,names,model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc4e646",
   "metadata": {},
   "source": [
    "# Age:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc34c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group columns into features (x) and labels (y), with their errors:\n",
    "y = data[['lp_zBEST', 'lp_age', 'lp_dust', 'lp_mass_best', 'lp_SFR_best']].copy()\n",
    "x = data[['HSC_g_FLUX_APER3', 'HSC_r_FLUX_APER3', 'HSC_i_FLUX_APER3',\n",
    "                 'HSC_z_FLUX_APER3', 'HSC_y_FLUX_APER3', 'UVISTA_Y_FLUX_APER3',\n",
    "                 'UVISTA_J_FLUX_APER3', 'UVISTA_H_FLUX_APER3', 'UVISTA_Ks_FLUX_APER3',\n",
    "                 'SC_IB427_FLUX_APER3', 'SC_IB464_FLUX_APER3', 'SC_IA484_FLUX_APER3',\n",
    "                 'SC_IB505_FLUX_APER3', 'SC_IA527_FLUX_APER3', 'SC_IB574_FLUX_APER3', \n",
    "                 'SC_IA624_FLUX_APER3', 'SC_IA679_FLUX_APER3', 'SC_IB709_FLUX_APER3', \n",
    "                 'SC_IA738_FLUX_APER3', 'SC_IA767_FLUX_APER3', 'SC_IB827_FLUX_APER3', \n",
    "                 'SC_NB711_FLUX_APER3', 'SC_NB816_FLUX_APER3', 'UVISTA_NB118_FLUX_APER3', \n",
    "                 'SC_B_FLUX_APER3', 'SC_gp_FLUX_APER3', 'SC_V_FLUX_APER3', 'SC_rp_FLUX_APER3', \n",
    "                 'SC_ip_FLUX_APER3', 'SC_zp_FLUX_APER3', 'SC_zpp_FLUX_APER3', 'HSC_g_FLUXERR_APER3', 'HSC_r_FLUXERR_APER3', 'HSC_i_FLUXERR_APER3',\n",
    "                 'HSC_z_FLUXERR_APER3', 'HSC_y_FLUXERR_APER3', 'UVISTA_Y_FLUXERR_APER3',\n",
    "                 'UVISTA_J_FLUXERR_APER3', 'UVISTA_H_FLUXERR_APER3', 'UVISTA_Ks_FLUXERR_APER3',\n",
    "                 'SC_IB427_FLUXERR_APER3', 'SC_IB464_FLUXERR_APER3', 'SC_IA484_FLUXERR_APER3',\n",
    "                 'SC_IB505_FLUXERR_APER3', 'SC_IA527_FLUXERR_APER3', 'SC_IB574_FLUXERR_APER3', \n",
    "                 'SC_IA624_FLUXERR_APER3', 'SC_IA679_FLUXERR_APER3', 'SC_IB709_FLUXERR_APER3', \n",
    "                 'SC_IA738_FLUXERR_APER3', 'SC_IA767_FLUXERR_APER3', 'SC_IB827_FLUXERR_APER3', \n",
    "                 'SC_NB711_FLUXERR_APER3', 'SC_NB816_FLUXERR_APER3', 'UVISTA_NB118_FLUXERR_APER3', \n",
    "                 'SC_B_FLUXERR_APER3', 'SC_gp_FLUXERR_APER3', 'SC_V_FLUXERR_APER3', 'SC_rp_FLUXERR_APER3', \n",
    "                 'SC_ip_FLUXERR_APER3', 'SC_zp_FLUXERR_APER3', 'SC_zpp_FLUXERR_APER3']].copy()\n",
    "y_z_err = data[['lp_chi2_best']].copy()\n",
    "x_err = data[['HSC_g_FLUXERR_APER3', 'HSC_r_FLUXERR_APER3', 'HSC_i_FLUXERR_APER3',\n",
    "                 'HSC_z_FLUXERR_APER3', 'HSC_y_FLUXERR_APER3', 'UVISTA_Y_FLUXERR_APER3',\n",
    "                 'UVISTA_J_FLUXERR_APER3', 'UVISTA_H_FLUXERR_APER3', 'UVISTA_Ks_FLUXERR_APER3',\n",
    "                 'SC_IB427_FLUXERR_APER3', 'SC_IB464_FLUXERR_APER3', 'SC_IA484_FLUXERR_APER3',\n",
    "                 'SC_IB505_FLUXERR_APER3', 'SC_IA527_FLUXERR_APER3', 'SC_IB574_FLUXERR_APER3', \n",
    "                 'SC_IA624_FLUXERR_APER3', 'SC_IA679_FLUXERR_APER3', 'SC_IB709_FLUXERR_APER3', \n",
    "                 'SC_IA738_FLUXERR_APER3', 'SC_IA767_FLUXERR_APER3', 'SC_IB827_FLUXERR_APER3', \n",
    "                 'SC_NB711_FLUXERR_APER3', 'SC_NB816_FLUXERR_APER3', 'UVISTA_NB118_FLUXERR_APER3', \n",
    "                 'SC_B_FLUXERR_APER3', 'SC_gp_FLUXERR_APER3', 'SC_V_FLUXERR_APER3', 'SC_rp_FLUXERR_APER3', \n",
    "                 'SC_ip_FLUXERR_APER3', 'SC_zp_FLUXERR_APER3', 'SC_zpp_FLUXERR_APER3']].copy()\n",
    "\n",
    "#Train validation test split:\n",
    "x_train, x_testval, y_train, y_testval, x_err_train, x_err_testval = train_test_split(x, y, x_err, test_size=0.3, shuffle = True)\n",
    "x_test, x_val, y_test, y_val , x_err_test, x_err_val = train_test_split(x_testval, y_testval, x_err_testval, test_size=0.5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff2f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['lp_age'] #Ages\n",
    "y_val = y_val['lp_age']\n",
    "y_test = y_test['lp_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3147ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "def metric_scores_rgr(x,y):\n",
    "    \"\"\"Computes the NMAD, bias, outlier fraction for the regression tasks\n",
    "    x: ground-truth data\n",
    "    y: predicted data\n",
    "    \"\"\"\n",
    "    met = np.abs(pd.Series(y-x))\n",
    "    f_out = met/(1+x.astype(np.float32))\n",
    "    nmad=1.48*np.median(f_out)\n",
    "    bias = np.median(f_out)\n",
    "    y_outlier = pd.Series(np.where(f_out > 0.30, 'outlier', 'not outlier'))\n",
    "    r2 = sklearn.metrics.r2_score(x, y)\n",
    "    #print(\"Outliers: \\n\", y_outlier.value_counts())\n",
    "    outlier_fraction = y_outlier.value_counts()['outlier'] / len(y_outlier)\n",
    "    #print(\"Outlier fraction: \\n\", outlier_fraction)\n",
    "    #print(\"\\n Bias: \\n\", bias)\n",
    "    #print(\"\\n NMAD score: \\n\", nmad)\n",
    "    #print('\\n R2 Test: \\n', r2)\n",
    "    return outlier_fraction, nmad, bias, r2\n",
    "\n",
    "metrics = {'n_estimators': [], 'max_depth': [], 'outlier_fraction': [], 'NMAD': [], 'bias': [], 'r2': []}\n",
    "metrics = pd.DataFrame(data=metrics)\n",
    "for i in [50, 100, 150]:\n",
    "    for j in [0, 4, 7, 9]:\n",
    "        metrics['n_estimators']\n",
    "        model = catboost.CatBoostRegressor(n_estimators = i, max_depth = j, verbose = 0)\n",
    "        model.fit(x_train, y_train, sample_weight = x_err_train) # sample_weight = x_err_train\n",
    "        pred_z = model.predict(x_val)\n",
    "        # Tests for metric tuning:\n",
    "        outlier_fraction, nmad, bias, r2 = metric_scores_rgr(y_val, pred_z)\n",
    "        new_row = pd.DataFrame([[i, j, outlier_fraction, nmad, bias, r2]], columns=['n_estimators', 'max_depth', 'outlier_fraction', 'NMAD', 'bias', 'r2'])\n",
    "        metrics = pd.concat([metrics, new_row], axis = 0)\n",
    "        \n",
    "print(metrics)\n",
    "\n",
    "total_time = (time.time() - start)\n",
    "print(f'Total needed time for catboost: {total_time/60} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d76eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:\n",
    "\n",
    "model = catboost.CatBoostRegressor(n_estimators = 150, max_depth = 9, verbose = 0)\n",
    "model.fit(x_train, y_train, sample_weight = x_err_train) # sample_weight = x_err_train\n",
    "pred_z = model.predict(x_test)\n",
    "#Metrics:\n",
    "outlier_fraction, nmad, bias, r2 = metric_scores_rgr(y_test, pred_z)\n",
    "print(\"Outlier fraction: \\n\", outlier_fraction)\n",
    "print(\"\\n Bias: \\n\", bias)\n",
    "print(\"\\n NMAD score: \\n\", nmad)\n",
    "print('\\n R2 Test: \\n', r2)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(y_test, pred_z)\n",
    "plt.title('Predicted vs. reference age for test dataset')\n",
    "plt.xlabel('data age lp_age')\n",
    "plt.ylabel('predicted age')\n",
    "x0, x1 = np.min(y_test), np.max(y_test)\n",
    "y0, y1 = np.min(y_test), np.max(y_test)\n",
    "plt.plot([np.min(y_test)-0.3*(1+np.min(y_test)), np.max(y_test)-0.30*(np.max(y_test)+1)], [y0, y1], color = 'red', linewidth = 2, linestyle = 'dashed')\n",
    "plt.plot([np.min(y_test)+0.3*(1+np.min(y_test)), np.max(y_test)+0.30*(np.max(y_test)+1)], [y0, y1], color = 'red', linewidth = 2, linestyle = 'dashed')\n",
    "plt.plot([x0, x1], [y0, y1], color = 'black', linewidth = 2)\n",
    "\n",
    "\n",
    "# Histogram:\n",
    "fig_hist = plt.figure(figsize=(7,5))\n",
    "plt.hist(pred_z, 20,facecolor='orange', edgecolor = 'black', alpha=0.5, label = 'predicted ages')\n",
    "plt.hist(y_test, 20, facecolor='blue', edgecolor = 'black', alpha=0.5, label = 'catalog ages')\n",
    "plt.xlabel('age')\n",
    "plt.legend()\n",
    "# Residuals:\n",
    "residuals = y_test - pred_z\n",
    "fig_res = plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_test, residuals, alpha = 0.5, edgecolor = 'black')\n",
    "plt.xlabel('catalog age')\n",
    "plt.ylabel('residuals (lp_age - pred_age)')\n",
    "x0, x1 = np.min(y_test), np.max(y_test)\n",
    "y0, y1 = 0, 0\n",
    "plt.plot([x0, x1], [y0, y1], color = 'black', linewidth = 2, linestyle = 'dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d51cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance:\n",
    "def plot_feature_importance(importance,names,model_type):\n",
    "    \"\"\"Plots feature importance\n",
    "    importance: features importance output from model\n",
    "    names: features names\n",
    "    model_type: name of the model used to compute features importance\n",
    "    \"\"\"\n",
    "\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False, inplace=True)\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(20,20))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title(model_type + ' Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Names')\n",
    "\n",
    "features_importances = model.feature_importances_ #replace model by your model\n",
    "names = np.array(['HSC_g_FLUX_APER3', 'HSC_r_FLUX_APER3', 'HSC_i_FLUX_APER3',\n",
    "                 'HSC_z_FLUX_APER3', 'HSC_y_FLUX_APER3', 'UVISTA_Y_FLUX_APER3',\n",
    "                 'UVISTA_J_FLUX_APER3', 'UVISTA_H_FLUX_APER3', 'UVISTA_Ks_FLUX_APER3',\n",
    "                 'SC_IB427_FLUX_APER3', 'SC_IB464_FLUX_APER3', 'SC_IA484_FLUX_APER3',\n",
    "                 'SC_IB505_FLUX_APER3', 'SC_IA527_FLUX_APER3', 'SC_IB574_FLUX_APER3', \n",
    "                 'SC_IA624_FLUX_APER3', 'SC_IA679_FLUX_APER3', 'SC_IB709_FLUX_APER3', \n",
    "                 'SC_IA738_FLUX_APER3', 'SC_IA767_FLUX_APER3', 'SC_IB827_FLUX_APER3', \n",
    "                 'SC_NB711_FLUX_APER3', 'SC_NB816_FLUX_APER3', 'UVISTA_NB118_FLUX_APER3', \n",
    "                 'SC_B_FLUX_APER3', 'SC_gp_FLUX_APER3', 'SC_V_FLUX_APER3', 'SC_rp_FLUX_APER3', \n",
    "                 'SC_ip_FLUX_APER3', 'SC_zp_FLUX_APER3', 'SC_zpp_FLUX_APER3', 'HSC_g_FLUXERR_APER3', 'HSC_r_FLUXERR_APER3', 'HSC_i_FLUXERR_APER3',\n",
    "                 'HSC_z_FLUXERR_APER3', 'HSC_y_FLUXERR_APER3', 'UVISTA_Y_FLUXERR_APER3',\n",
    "                 'UVISTA_J_FLUXERR_APER3', 'UVISTA_H_FLUXERR_APER3', 'UVISTA_Ks_FLUXERR_APER3',\n",
    "                 'SC_IB427_FLUXERR_APER3', 'SC_IB464_FLUXERR_APER3', 'SC_IA484_FLUXERR_APER3',\n",
    "                 'SC_IB505_FLUXERR_APER3', 'SC_IA527_FLUXERR_APER3', 'SC_IB574_FLUXERR_APER3', \n",
    "                 'SC_IA624_FLUXERR_APER3', 'SC_IA679_FLUXERR_APER3', 'SC_IB709_FLUXERR_APER3', \n",
    "                 'SC_IA738_FLUXERR_APER3', 'SC_IA767_FLUXERR_APER3', 'SC_IB827_FLUXERR_APER3', \n",
    "                 'SC_NB711_FLUXERR_APER3', 'SC_NB816_FLUXERR_APER3', 'UVISTA_NB118_FLUXERR_APER3', \n",
    "                 'SC_B_FLUXERR_APER3', 'SC_gp_FLUXERR_APER3', 'SC_V_FLUXERR_APER3', 'SC_rp_FLUXERR_APER3', \n",
    "                 'SC_ip_FLUXERR_APER3', 'SC_zp_FLUXERR_APER3', 'SC_zpp_FLUXERR_APER3'])#list of the columns from the X_train data set\n",
    "model_type = 'CatBoost' # change according to the model to be used. Only used in the plots.\n",
    "\n",
    "plot_feature_importance(features_importances,names,model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4dd868",
   "metadata": {},
   "source": [
    "# Dust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb0aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group columns into features (x) and labels (y), with their errors:\n",
    "y = data[['lp_zBEST', 'lp_age', 'lp_dust', 'lp_mass_best', 'lp_SFR_best']].copy()\n",
    "x = data[['HSC_g_FLUX_APER3', 'HSC_r_FLUX_APER3', 'HSC_i_FLUX_APER3',\n",
    "                 'HSC_z_FLUX_APER3', 'HSC_y_FLUX_APER3', 'UVISTA_Y_FLUX_APER3',\n",
    "                 'UVISTA_J_FLUX_APER3', 'UVISTA_H_FLUX_APER3', 'UVISTA_Ks_FLUX_APER3',\n",
    "                 'SC_IB427_FLUX_APER3', 'SC_IB464_FLUX_APER3', 'SC_IA484_FLUX_APER3',\n",
    "                 'SC_IB505_FLUX_APER3', 'SC_IA527_FLUX_APER3', 'SC_IB574_FLUX_APER3', \n",
    "                 'SC_IA624_FLUX_APER3', 'SC_IA679_FLUX_APER3', 'SC_IB709_FLUX_APER3', \n",
    "                 'SC_IA738_FLUX_APER3', 'SC_IA767_FLUX_APER3', 'SC_IB827_FLUX_APER3', \n",
    "                 'SC_NB711_FLUX_APER3', 'SC_NB816_FLUX_APER3', 'UVISTA_NB118_FLUX_APER3', \n",
    "                 'SC_B_FLUX_APER3', 'SC_gp_FLUX_APER3', 'SC_V_FLUX_APER3', 'SC_rp_FLUX_APER3', \n",
    "                 'SC_ip_FLUX_APER3', 'SC_zp_FLUX_APER3', 'SC_zpp_FLUX_APER3', 'HSC_g_FLUXERR_APER3', 'HSC_r_FLUXERR_APER3', 'HSC_i_FLUXERR_APER3',\n",
    "                 'HSC_z_FLUXERR_APER3', 'HSC_y_FLUXERR_APER3', 'UVISTA_Y_FLUXERR_APER3',\n",
    "                 'UVISTA_J_FLUXERR_APER3', 'UVISTA_H_FLUXERR_APER3', 'UVISTA_Ks_FLUXERR_APER3',\n",
    "                 'SC_IB427_FLUXERR_APER3', 'SC_IB464_FLUXERR_APER3', 'SC_IA484_FLUXERR_APER3',\n",
    "                 'SC_IB505_FLUXERR_APER3', 'SC_IA527_FLUXERR_APER3', 'SC_IB574_FLUXERR_APER3', \n",
    "                 'SC_IA624_FLUXERR_APER3', 'SC_IA679_FLUXERR_APER3', 'SC_IB709_FLUXERR_APER3', \n",
    "                 'SC_IA738_FLUXERR_APER3', 'SC_IA767_FLUXERR_APER3', 'SC_IB827_FLUXERR_APER3', \n",
    "                 'SC_NB711_FLUXERR_APER3', 'SC_NB816_FLUXERR_APER3', 'UVISTA_NB118_FLUXERR_APER3', \n",
    "                 'SC_B_FLUXERR_APER3', 'SC_gp_FLUXERR_APER3', 'SC_V_FLUXERR_APER3', 'SC_rp_FLUXERR_APER3', \n",
    "                 'SC_ip_FLUXERR_APER3', 'SC_zp_FLUXERR_APER3', 'SC_zpp_FLUXERR_APER3']].copy()\n",
    "y_z_err = data[['lp_chi2_best']].copy()\n",
    "x_err = data[['HSC_g_FLUXERR_APER3', 'HSC_r_FLUXERR_APER3', 'HSC_i_FLUXERR_APER3',\n",
    "                 'HSC_z_FLUXERR_APER3', 'HSC_y_FLUXERR_APER3', 'UVISTA_Y_FLUXERR_APER3',\n",
    "                 'UVISTA_J_FLUXERR_APER3', 'UVISTA_H_FLUXERR_APER3', 'UVISTA_Ks_FLUXERR_APER3',\n",
    "                 'SC_IB427_FLUXERR_APER3', 'SC_IB464_FLUXERR_APER3', 'SC_IA484_FLUXERR_APER3',\n",
    "                 'SC_IB505_FLUXERR_APER3', 'SC_IA527_FLUXERR_APER3', 'SC_IB574_FLUXERR_APER3', \n",
    "                 'SC_IA624_FLUXERR_APER3', 'SC_IA679_FLUXERR_APER3', 'SC_IB709_FLUXERR_APER3', \n",
    "                 'SC_IA738_FLUXERR_APER3', 'SC_IA767_FLUXERR_APER3', 'SC_IB827_FLUXERR_APER3', \n",
    "                 'SC_NB711_FLUXERR_APER3', 'SC_NB816_FLUXERR_APER3', 'UVISTA_NB118_FLUXERR_APER3', \n",
    "                 'SC_B_FLUXERR_APER3', 'SC_gp_FLUXERR_APER3', 'SC_V_FLUXERR_APER3', 'SC_rp_FLUXERR_APER3', \n",
    "                 'SC_ip_FLUXERR_APER3', 'SC_zp_FLUXERR_APER3', 'SC_zpp_FLUXERR_APER3']].copy()\n",
    "\n",
    "#Train validation test split:\n",
    "x_train, x_testval, y_train, y_testval, x_err_train, x_err_testval = train_test_split(x, y, x_err, test_size=0.3, shuffle = True)\n",
    "x_test, x_val, y_test, y_val , x_err_test, x_err_val = train_test_split(x_testval, y_testval, x_err_testval, test_size=0.5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5005f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['lp_dust'] #Dust\n",
    "y_val = y_val['lp_dust']\n",
    "y_test = y_test['lp_dust']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ddd62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "def metric_scores_rgr(x,y):\n",
    "    \"\"\"Computes the NMAD, bias, outlier fraction for the regression tasks\n",
    "    x: ground-truth data\n",
    "    y: predicted data\n",
    "    \"\"\"\n",
    "    met = np.abs(pd.Series(y-x))\n",
    "    f_out = met/(1+x.astype(np.float32))\n",
    "    nmad=1.48*np.median(f_out)\n",
    "    bias = np.median(f_out)\n",
    "    y_outlier = pd.Series(np.where(f_out > 0.30, 'outlier', 'not outlier'))\n",
    "    r2 = sklearn.metrics.r2_score(x, y)\n",
    "    #print(\"Outliers: \\n\", y_outlier.value_counts())\n",
    "    outlier_fraction = y_outlier.value_counts()['outlier'] / len(y_outlier)\n",
    "    #print(\"Outlier fraction: \\n\", outlier_fraction)\n",
    "    #print(\"\\n Bias: \\n\", bias)\n",
    "    #print(\"\\n NMAD score: \\n\", nmad)\n",
    "    #print('\\n R2 Test: \\n', r2)\n",
    "    return outlier_fraction, nmad, bias, r2\n",
    "\n",
    "\n",
    "metrics = {'n_estimators': [], 'max_depth': [], 'outlier_fraction': [], 'NMAD': [], 'bias': [], 'r2': []}\n",
    "metrics = pd.DataFrame(data=metrics)\n",
    "for i in [50, 100, 150]:\n",
    "    for j in [0, 4, 7, 9]:\n",
    "        metrics['n_estimators']\n",
    "        model = catboost.CatBoostRegressor(n_estimators = i, max_depth = j, verbose = 0)\n",
    "        model.fit(x_train, y_train, sample_weight = x_err_train) # sample_weight = x_err_train\n",
    "        pred_z = model.predict(x_val)\n",
    "        # Tests for metric tuning:\n",
    "        outlier_fraction, nmad, bias, r2 = metric_scores_rgr(y_val, pred_z)\n",
    "        new_row = pd.DataFrame([[i, j, outlier_fraction, nmad, bias, r2]], columns=['n_estimators', 'max_depth', 'outlier_fraction', 'NMAD', 'bias', 'r2'])\n",
    "        metrics = pd.concat([metrics, new_row], axis = 0)\n",
    "        \n",
    "print(metrics)\n",
    "\n",
    "total_time = (time.time() - start)\n",
    "print(f'Total needed time for catboost: {total_time/60} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97edce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:\n",
    "\n",
    "model = catboost.CatBoostRegressor(n_estimators = 150, max_depth = 9, verbose = 0)\n",
    "model.fit(x_train, y_train, sample_weight = x_err_train) # sample_weight = x_err_train\n",
    "pred_z = model.predict(x_test)\n",
    "#Metrics:\n",
    "outlier_fraction, nmad, bias, r2 = metric_scores_rgr(y_test, pred_z)\n",
    "print(\"Outlier fraction: \\n\", outlier_fraction)\n",
    "print(\"\\n Bias: \\n\", bias)\n",
    "print(\"\\n NMAD score: \\n\", nmad)\n",
    "print('\\n R2 Test: \\n', r2)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(y_test, pred_z)\n",
    "plt.title('Predicted vs. reference dust for test dataset')\n",
    "plt.xlabel('data dust lp_dust')\n",
    "plt.ylabel('predicted dust')\n",
    "x0, x1 = np.min(y_test), np.max(y_test)\n",
    "y0, y1 = np.min(y_test), np.max(y_test)\n",
    "plt.plot([np.min(y_test)-0.3*(1+np.min(y_test)), np.max(y_test)-0.30*(np.max(y_test)+1)], [y0, y1], color = 'red', linewidth = 2, linestyle = 'dashed')\n",
    "plt.plot([np.min(y_test)+0.3*(1+np.min(y_test)), np.max(y_test)+0.30*(np.max(y_test)+1)], [y0, y1], color = 'red', linewidth = 2, linestyle = 'dashed')\n",
    "plt.plot([x0, x1], [y0, y1], color = 'black', linewidth = 2)\n",
    "\n",
    "\n",
    "# Histogram:\n",
    "fig_hist = plt.figure(figsize=(7,5))\n",
    "plt.hist(pred_z, 8,facecolor='orange', edgecolor = 'black', alpha=0.5, label = 'predicted dust')\n",
    "plt.hist(y_test, 8, facecolor='blue', edgecolor = 'black', alpha=0.5, label = 'catalog dust')\n",
    "plt.xlabel('dust')\n",
    "plt.legend()\n",
    "# Residuals:\n",
    "residuals = y_test - pred_z\n",
    "fig_res = plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_test, residuals, alpha = 0.5, edgecolor = 'black')\n",
    "plt.xlabel('catalog dust')\n",
    "plt.ylabel('residuals (lp_dust - pred_dust)')\n",
    "x0, x1 = np.min(y_test), np.max(y_test)\n",
    "y0, y1 = 0, 0\n",
    "plt.plot([x0, x1], [y0, y1], color = 'black', linewidth = 2, linestyle = 'dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2823a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance:\n",
    "def plot_feature_importance(importance,names,model_type):\n",
    "    \"\"\"Plots feature importance\n",
    "    importance: features importance output from model\n",
    "    names: features names\n",
    "    model_type: name of the model used to compute features importance\n",
    "    \"\"\"\n",
    "\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False, inplace=True)\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(20,20))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title(model_type + ' Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Names')\n",
    "\n",
    "features_importances = model.feature_importances_ #replace model by your model\n",
    "names = np.array(['HSC_g_FLUX_APER3', 'HSC_r_FLUX_APER3', 'HSC_i_FLUX_APER3',\n",
    "                 'HSC_z_FLUX_APER3', 'HSC_y_FLUX_APER3', 'UVISTA_Y_FLUX_APER3',\n",
    "                 'UVISTA_J_FLUX_APER3', 'UVISTA_H_FLUX_APER3', 'UVISTA_Ks_FLUX_APER3',\n",
    "                 'SC_IB427_FLUX_APER3', 'SC_IB464_FLUX_APER3', 'SC_IA484_FLUX_APER3',\n",
    "                 'SC_IB505_FLUX_APER3', 'SC_IA527_FLUX_APER3', 'SC_IB574_FLUX_APER3', \n",
    "                 'SC_IA624_FLUX_APER3', 'SC_IA679_FLUX_APER3', 'SC_IB709_FLUX_APER3', \n",
    "                 'SC_IA738_FLUX_APER3', 'SC_IA767_FLUX_APER3', 'SC_IB827_FLUX_APER3', \n",
    "                 'SC_NB711_FLUX_APER3', 'SC_NB816_FLUX_APER3', 'UVISTA_NB118_FLUX_APER3', \n",
    "                 'SC_B_FLUX_APER3', 'SC_gp_FLUX_APER3', 'SC_V_FLUX_APER3', 'SC_rp_FLUX_APER3', \n",
    "                 'SC_ip_FLUX_APER3', 'SC_zp_FLUX_APER3', 'SC_zpp_FLUX_APER3', 'HSC_g_FLUXERR_APER3', 'HSC_r_FLUXERR_APER3', 'HSC_i_FLUXERR_APER3',\n",
    "                 'HSC_z_FLUXERR_APER3', 'HSC_y_FLUXERR_APER3', 'UVISTA_Y_FLUXERR_APER3',\n",
    "                 'UVISTA_J_FLUXERR_APER3', 'UVISTA_H_FLUXERR_APER3', 'UVISTA_Ks_FLUXERR_APER3',\n",
    "                 'SC_IB427_FLUXERR_APER3', 'SC_IB464_FLUXERR_APER3', 'SC_IA484_FLUXERR_APER3',\n",
    "                 'SC_IB505_FLUXERR_APER3', 'SC_IA527_FLUXERR_APER3', 'SC_IB574_FLUXERR_APER3', \n",
    "                 'SC_IA624_FLUXERR_APER3', 'SC_IA679_FLUXERR_APER3', 'SC_IB709_FLUXERR_APER3', \n",
    "                 'SC_IA738_FLUXERR_APER3', 'SC_IA767_FLUXERR_APER3', 'SC_IB827_FLUXERR_APER3', \n",
    "                 'SC_NB711_FLUXERR_APER3', 'SC_NB816_FLUXERR_APER3', 'UVISTA_NB118_FLUXERR_APER3', \n",
    "                 'SC_B_FLUXERR_APER3', 'SC_gp_FLUXERR_APER3', 'SC_V_FLUXERR_APER3', 'SC_rp_FLUXERR_APER3', \n",
    "                 'SC_ip_FLUXERR_APER3', 'SC_zp_FLUXERR_APER3', 'SC_zpp_FLUXERR_APER3'])#list of the columns from the X_train data set\n",
    "model_type = 'CatBoost' # change according to the model to be used. Only used in the plots.\n",
    "\n",
    "plot_feature_importance(features_importances,names,model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3875872",
   "metadata": {},
   "source": [
    "# Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cac236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group columns into features (x) and labels (y), with their errors:\n",
    "y = data[['lp_zBEST', 'lp_age', 'lp_dust', 'lp_mass_best', 'lp_SFR_best']].copy()\n",
    "x = data[['HSC_g_FLUX_APER3', 'HSC_r_FLUX_APER3', 'HSC_i_FLUX_APER3',\n",
    "                 'HSC_z_FLUX_APER3', 'HSC_y_FLUX_APER3', 'UVISTA_Y_FLUX_APER3',\n",
    "                 'UVISTA_J_FLUX_APER3', 'UVISTA_H_FLUX_APER3', 'UVISTA_Ks_FLUX_APER3',\n",
    "                 'SC_IB427_FLUX_APER3', 'SC_IB464_FLUX_APER3', 'SC_IA484_FLUX_APER3',\n",
    "                 'SC_IB505_FLUX_APER3', 'SC_IA527_FLUX_APER3', 'SC_IB574_FLUX_APER3', \n",
    "                 'SC_IA624_FLUX_APER3', 'SC_IA679_FLUX_APER3', 'SC_IB709_FLUX_APER3', \n",
    "                 'SC_IA738_FLUX_APER3', 'SC_IA767_FLUX_APER3', 'SC_IB827_FLUX_APER3', \n",
    "                 'SC_NB711_FLUX_APER3', 'SC_NB816_FLUX_APER3', 'UVISTA_NB118_FLUX_APER3', \n",
    "                 'SC_B_FLUX_APER3', 'SC_gp_FLUX_APER3', 'SC_V_FLUX_APER3', 'SC_rp_FLUX_APER3', \n",
    "                 'SC_ip_FLUX_APER3', 'SC_zp_FLUX_APER3', 'SC_zpp_FLUX_APER3', 'HSC_g_FLUXERR_APER3', 'HSC_r_FLUXERR_APER3', 'HSC_i_FLUXERR_APER3',\n",
    "                 'HSC_z_FLUXERR_APER3', 'HSC_y_FLUXERR_APER3', 'UVISTA_Y_FLUXERR_APER3',\n",
    "                 'UVISTA_J_FLUXERR_APER3', 'UVISTA_H_FLUXERR_APER3', 'UVISTA_Ks_FLUXERR_APER3',\n",
    "                 'SC_IB427_FLUXERR_APER3', 'SC_IB464_FLUXERR_APER3', 'SC_IA484_FLUXERR_APER3',\n",
    "                 'SC_IB505_FLUXERR_APER3', 'SC_IA527_FLUXERR_APER3', 'SC_IB574_FLUXERR_APER3', \n",
    "                 'SC_IA624_FLUXERR_APER3', 'SC_IA679_FLUXERR_APER3', 'SC_IB709_FLUXERR_APER3', \n",
    "                 'SC_IA738_FLUXERR_APER3', 'SC_IA767_FLUXERR_APER3', 'SC_IB827_FLUXERR_APER3', \n",
    "                 'SC_NB711_FLUXERR_APER3', 'SC_NB816_FLUXERR_APER3', 'UVISTA_NB118_FLUXERR_APER3', \n",
    "                 'SC_B_FLUXERR_APER3', 'SC_gp_FLUXERR_APER3', 'SC_V_FLUXERR_APER3', 'SC_rp_FLUXERR_APER3', \n",
    "                 'SC_ip_FLUXERR_APER3', 'SC_zp_FLUXERR_APER3', 'SC_zpp_FLUXERR_APER3']].copy()\n",
    "y_z_err = data[['lp_chi2_best']].copy()\n",
    "x_err = data[['HSC_g_FLUXERR_APER3', 'HSC_r_FLUXERR_APER3', 'HSC_i_FLUXERR_APER3',\n",
    "                 'HSC_z_FLUXERR_APER3', 'HSC_y_FLUXERR_APER3', 'UVISTA_Y_FLUXERR_APER3',\n",
    "                 'UVISTA_J_FLUXERR_APER3', 'UVISTA_H_FLUXERR_APER3', 'UVISTA_Ks_FLUXERR_APER3',\n",
    "                 'SC_IB427_FLUXERR_APER3', 'SC_IB464_FLUXERR_APER3', 'SC_IA484_FLUXERR_APER3',\n",
    "                 'SC_IB505_FLUXERR_APER3', 'SC_IA527_FLUXERR_APER3', 'SC_IB574_FLUXERR_APER3', \n",
    "                 'SC_IA624_FLUXERR_APER3', 'SC_IA679_FLUXERR_APER3', 'SC_IB709_FLUXERR_APER3', \n",
    "                 'SC_IA738_FLUXERR_APER3', 'SC_IA767_FLUXERR_APER3', 'SC_IB827_FLUXERR_APER3', \n",
    "                 'SC_NB711_FLUXERR_APER3', 'SC_NB816_FLUXERR_APER3', 'UVISTA_NB118_FLUXERR_APER3', \n",
    "                 'SC_B_FLUXERR_APER3', 'SC_gp_FLUXERR_APER3', 'SC_V_FLUXERR_APER3', 'SC_rp_FLUXERR_APER3', \n",
    "                 'SC_ip_FLUXERR_APER3', 'SC_zp_FLUXERR_APER3', 'SC_zpp_FLUXERR_APER3']].copy()\n",
    "\n",
    "#Train validation test split:\n",
    "x_train, x_testval, y_train, y_testval, x_err_train, x_err_testval = train_test_split(x, y, x_err, test_size=0.3, shuffle = True)\n",
    "x_test, x_val, y_test, y_val , x_err_test, x_err_val = train_test_split(x_testval, y_testval, x_err_testval, test_size=0.5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e0656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['lp_mass_best'] #Masses\n",
    "y_val = y_val['lp_mass_best']\n",
    "y_test = y_test['lp_mass_best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babe5cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "def metric_scores_rgr(x,y):\n",
    "    \"\"\"Computes the NMAD, bias, outlier fraction for the regression tasks\n",
    "    x: ground-truth data\n",
    "    y: predicted data\n",
    "    \"\"\"\n",
    "    met = np.abs(pd.Series(y-x))\n",
    "    f_out = met/(1+x.astype(np.float32))\n",
    "    nmad=1.48*np.median(f_out)\n",
    "    bias = np.median(f_out)\n",
    "    y_outlier = pd.Series(np.where(f_out > 0.30, 'outlier', 'not outlier'))\n",
    "    r2 = sklearn.metrics.r2_score(x, y)\n",
    "    #print(\"Outliers: \\n\", y_outlier.value_counts())\n",
    "    outlier_fraction = y_outlier.value_counts()['outlier'] / len(y_outlier)\n",
    "    #print(\"Outlier fraction: \\n\", outlier_fraction)\n",
    "    #print(\"\\n Bias: \\n\", bias)\n",
    "    #print(\"\\n NMAD score: \\n\", nmad)\n",
    "    #print('\\n R2 Test: \\n', r2)\n",
    "    return outlier_fraction, nmad, bias, r2\n",
    "\n",
    "metrics = {'n_estimators': [], 'max_depth': [], 'outlier_fraction': [], 'NMAD': [], 'bias': [], 'r2': []}\n",
    "metrics = pd.DataFrame(data=metrics)\n",
    "for i in [50, 100, 150]:\n",
    "    for j in [0, 4, 7, 9]:\n",
    "        metrics['n_estimators']\n",
    "        model = catboost.CatBoostRegressor(n_estimators = i, max_depth = j, verbose = 0)\n",
    "        model.fit(x_train, y_train, sample_weight = x_err_train) # sample_weight = x_err_train\n",
    "        pred_z = model.predict(x_val)\n",
    "        # Tests for metric tuning:\n",
    "        outlier_fraction, nmad, bias, r2 = metric_scores_rgr(y_val, pred_z)\n",
    "        new_row = pd.DataFrame([[i, j, outlier_fraction, nmad, bias, r2]], columns=['n_estimators', 'max_depth', 'outlier_fraction', 'NMAD', 'bias', 'r2'])\n",
    "        metrics = pd.concat([metrics, new_row], axis = 0)\n",
    "        \n",
    "print(metrics)\n",
    "\n",
    "total_time = (time.time() - start)\n",
    "print(f'Total needed time for catboost: {total_time/60} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de385b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:\n",
    "\n",
    "model = catboost.CatBoostRegressor(n_estimators = 150, max_depth = 9, verbose = 0)\n",
    "model.fit(x_train, y_train, sample_weight = x_err_train) # sample_weight = x_err_train\n",
    "pred_z = model.predict(x_test)\n",
    "#Metrics:\n",
    "outlier_fraction, nmad, bias, r2 = metric_scores_rgr(y_test, pred_z)\n",
    "print(\"Outlier fraction: \\n\", outlier_fraction)\n",
    "print(\"\\n Bias: \\n\", bias)\n",
    "print(\"\\n NMAD score: \\n\", nmad)\n",
    "print('\\n R2 Test: \\n', r2)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(y_test, pred_z)\n",
    "plt.title('Predicted vs. reference mass for test dataset')\n",
    "plt.xlabel('data mass lp_mass_best')\n",
    "plt.ylabel('predicted mass')\n",
    "x0, x1 = np.min(y_test), np.max(y_test)\n",
    "y0, y1 = np.min(y_test), np.max(y_test)\n",
    "plt.xlim(np.min(y_test), np.max(y_test))\n",
    "plt.ylim(np.min(y_test), np.max(y_test))\n",
    "plt.plot([np.min(y_test)-0.3*(1+np.min(y_test)), np.max(y_test)-0.30*(np.max(y_test)+1)], [y0, y1], color = 'red', linewidth = 2, linestyle = 'dashed')\n",
    "plt.plot([np.min(y_test)+0.3*(1+np.min(y_test)), np.max(y_test)+0.30*(np.max(y_test)+1)], [y0, y1], color = 'red', linewidth = 2, linestyle = 'dashed')\n",
    "plt.plot([x0, x1], [y0, y1], color = 'black', linewidth = 2)\n",
    "\n",
    "\n",
    "# Histogram:\n",
    "fig_hist = plt.figure(figsize=(7,5))\n",
    "plt.hist(pred_z, 20,facecolor='orange', edgecolor = 'black', alpha=0.5, label = 'predicted mass')\n",
    "plt.hist(y_test, 20, facecolor='blue', edgecolor = 'black', alpha=0.5, label = 'catalog mass')\n",
    "plt.xlabel('mass')\n",
    "plt.legend()\n",
    "# Residuals:\n",
    "residuals = y_test - pred_z\n",
    "fig_res = plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_test, residuals, alpha = 0.5, edgecolor = 'black')\n",
    "plt.xlabel('catalog mass')\n",
    "plt.ylabel('residuals (lp_mass - pred_mass)')\n",
    "x0, x1 = np.min(y_test), np.max(y_test)\n",
    "y0, y1 = 0, 0\n",
    "plt.plot([x0, x1], [y0, y1], color = 'black', linewidth = 2, linestyle = 'dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efccd4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance:\n",
    "def plot_feature_importance(importance,names,model_type):\n",
    "    \"\"\"Plots feature importance\n",
    "    importance: features importance output from model\n",
    "    names: features names\n",
    "    model_type: name of the model used to compute features importance\n",
    "    \"\"\"\n",
    "\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False, inplace=True)\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(20,20))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title(model_type + ' Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Names')\n",
    "\n",
    "features_importances = model.feature_importances_ #replace model by your model\n",
    "names = np.array(['HSC_g_FLUX_APER3', 'HSC_r_FLUX_APER3', 'HSC_i_FLUX_APER3',\n",
    "                 'HSC_z_FLUX_APER3', 'HSC_y_FLUX_APER3', 'UVISTA_Y_FLUX_APER3',\n",
    "                 'UVISTA_J_FLUX_APER3', 'UVISTA_H_FLUX_APER3', 'UVISTA_Ks_FLUX_APER3',\n",
    "                 'SC_IB427_FLUX_APER3', 'SC_IB464_FLUX_APER3', 'SC_IA484_FLUX_APER3',\n",
    "                 'SC_IB505_FLUX_APER3', 'SC_IA527_FLUX_APER3', 'SC_IB574_FLUX_APER3', \n",
    "                 'SC_IA624_FLUX_APER3', 'SC_IA679_FLUX_APER3', 'SC_IB709_FLUX_APER3', \n",
    "                 'SC_IA738_FLUX_APER3', 'SC_IA767_FLUX_APER3', 'SC_IB827_FLUX_APER3', \n",
    "                 'SC_NB711_FLUX_APER3', 'SC_NB816_FLUX_APER3', 'UVISTA_NB118_FLUX_APER3', \n",
    "                 'SC_B_FLUX_APER3', 'SC_gp_FLUX_APER3', 'SC_V_FLUX_APER3', 'SC_rp_FLUX_APER3', \n",
    "                 'SC_ip_FLUX_APER3', 'SC_zp_FLUX_APER3', 'SC_zpp_FLUX_APER3', 'HSC_g_FLUXERR_APER3', 'HSC_r_FLUXERR_APER3', 'HSC_i_FLUXERR_APER3',\n",
    "                 'HSC_z_FLUXERR_APER3', 'HSC_y_FLUXERR_APER3', 'UVISTA_Y_FLUXERR_APER3',\n",
    "                 'UVISTA_J_FLUXERR_APER3', 'UVISTA_H_FLUXERR_APER3', 'UVISTA_Ks_FLUXERR_APER3',\n",
    "                 'SC_IB427_FLUXERR_APER3', 'SC_IB464_FLUXERR_APER3', 'SC_IA484_FLUXERR_APER3',\n",
    "                 'SC_IB505_FLUXERR_APER3', 'SC_IA527_FLUXERR_APER3', 'SC_IB574_FLUXERR_APER3', \n",
    "                 'SC_IA624_FLUXERR_APER3', 'SC_IA679_FLUXERR_APER3', 'SC_IB709_FLUXERR_APER3', \n",
    "                 'SC_IA738_FLUXERR_APER3', 'SC_IA767_FLUXERR_APER3', 'SC_IB827_FLUXERR_APER3', \n",
    "                 'SC_NB711_FLUXERR_APER3', 'SC_NB816_FLUXERR_APER3', 'UVISTA_NB118_FLUXERR_APER3', \n",
    "                 'SC_B_FLUXERR_APER3', 'SC_gp_FLUXERR_APER3', 'SC_V_FLUXERR_APER3', 'SC_rp_FLUXERR_APER3', \n",
    "                 'SC_ip_FLUXERR_APER3', 'SC_zp_FLUXERR_APER3', 'SC_zpp_FLUXERR_APER3'])#list of the columns from the X_train data set\n",
    "model_type = 'CatBoost' # change according to the model to be used. Only used in the plots.\n",
    "\n",
    "plot_feature_importance(features_importances,names,model_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babc8064",
   "metadata": {},
   "source": [
    "# SFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b89108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group columns into features (x) and labels (y), with their errors:\n",
    "y = data[['lp_zBEST', 'lp_age', 'lp_dust', 'lp_mass_best', 'lp_SFR_best']].copy()\n",
    "x = data[['HSC_g_FLUX_APER3', 'HSC_r_FLUX_APER3', 'HSC_i_FLUX_APER3',\n",
    "                 'HSC_z_FLUX_APER3', 'HSC_y_FLUX_APER3', 'UVISTA_Y_FLUX_APER3',\n",
    "                 'UVISTA_J_FLUX_APER3', 'UVISTA_H_FLUX_APER3', 'UVISTA_Ks_FLUX_APER3',\n",
    "                 'SC_IB427_FLUX_APER3', 'SC_IB464_FLUX_APER3', 'SC_IA484_FLUX_APER3',\n",
    "                 'SC_IB505_FLUX_APER3', 'SC_IA527_FLUX_APER3', 'SC_IB574_FLUX_APER3', \n",
    "                 'SC_IA624_FLUX_APER3', 'SC_IA679_FLUX_APER3', 'SC_IB709_FLUX_APER3', \n",
    "                 'SC_IA738_FLUX_APER3', 'SC_IA767_FLUX_APER3', 'SC_IB827_FLUX_APER3', \n",
    "                 'SC_NB711_FLUX_APER3', 'SC_NB816_FLUX_APER3', 'UVISTA_NB118_FLUX_APER3', \n",
    "                 'SC_B_FLUX_APER3', 'SC_gp_FLUX_APER3', 'SC_V_FLUX_APER3', 'SC_rp_FLUX_APER3', \n",
    "                 'SC_ip_FLUX_APER3', 'SC_zp_FLUX_APER3', 'SC_zpp_FLUX_APER3', 'HSC_g_FLUXERR_APER3', 'HSC_r_FLUXERR_APER3', 'HSC_i_FLUXERR_APER3',\n",
    "                 'HSC_z_FLUXERR_APER3', 'HSC_y_FLUXERR_APER3', 'UVISTA_Y_FLUXERR_APER3',\n",
    "                 'UVISTA_J_FLUXERR_APER3', 'UVISTA_H_FLUXERR_APER3', 'UVISTA_Ks_FLUXERR_APER3',\n",
    "                 'SC_IB427_FLUXERR_APER3', 'SC_IB464_FLUXERR_APER3', 'SC_IA484_FLUXERR_APER3',\n",
    "                 'SC_IB505_FLUXERR_APER3', 'SC_IA527_FLUXERR_APER3', 'SC_IB574_FLUXERR_APER3', \n",
    "                 'SC_IA624_FLUXERR_APER3', 'SC_IA679_FLUXERR_APER3', 'SC_IB709_FLUXERR_APER3', \n",
    "                 'SC_IA738_FLUXERR_APER3', 'SC_IA767_FLUXERR_APER3', 'SC_IB827_FLUXERR_APER3', \n",
    "                 'SC_NB711_FLUXERR_APER3', 'SC_NB816_FLUXERR_APER3', 'UVISTA_NB118_FLUXERR_APER3', \n",
    "                 'SC_B_FLUXERR_APER3', 'SC_gp_FLUXERR_APER3', 'SC_V_FLUXERR_APER3', 'SC_rp_FLUXERR_APER3', \n",
    "                 'SC_ip_FLUXERR_APER3', 'SC_zp_FLUXERR_APER3', 'SC_zpp_FLUXERR_APER3']].copy()\n",
    "y_z_err = data[['lp_chi2_best']].copy()\n",
    "x_err = data[['HSC_g_FLUXERR_APER3', 'HSC_r_FLUXERR_APER3', 'HSC_i_FLUXERR_APER3',\n",
    "                 'HSC_z_FLUXERR_APER3', 'HSC_y_FLUXERR_APER3', 'UVISTA_Y_FLUXERR_APER3',\n",
    "                 'UVISTA_J_FLUXERR_APER3', 'UVISTA_H_FLUXERR_APER3', 'UVISTA_Ks_FLUXERR_APER3',\n",
    "                 'SC_IB427_FLUXERR_APER3', 'SC_IB464_FLUXERR_APER3', 'SC_IA484_FLUXERR_APER3',\n",
    "                 'SC_IB505_FLUXERR_APER3', 'SC_IA527_FLUXERR_APER3', 'SC_IB574_FLUXERR_APER3', \n",
    "                 'SC_IA624_FLUXERR_APER3', 'SC_IA679_FLUXERR_APER3', 'SC_IB709_FLUXERR_APER3', \n",
    "                 'SC_IA738_FLUXERR_APER3', 'SC_IA767_FLUXERR_APER3', 'SC_IB827_FLUXERR_APER3', \n",
    "                 'SC_NB711_FLUXERR_APER3', 'SC_NB816_FLUXERR_APER3', 'UVISTA_NB118_FLUXERR_APER3', \n",
    "                 'SC_B_FLUXERR_APER3', 'SC_gp_FLUXERR_APER3', 'SC_V_FLUXERR_APER3', 'SC_rp_FLUXERR_APER3', \n",
    "                 'SC_ip_FLUXERR_APER3', 'SC_zp_FLUXERR_APER3', 'SC_zpp_FLUXERR_APER3']].copy()\n",
    "\n",
    "#Train validation test split:\n",
    "x_train, x_testval, y_train, y_testval, x_err_train, x_err_testval = train_test_split(x, y, x_err, test_size=0.3, shuffle = True)\n",
    "x_test, x_val, y_test, y_val , x_err_test, x_err_val = train_test_split(x_testval, y_testval, x_err_testval, test_size=0.5, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9140b2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train['lp_SFR_best'] #SFR\n",
    "y_val = y_val['lp_SFR_best']\n",
    "y_test = y_test['lp_SFR_best']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942a5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "def metric_scores_rgr(x,y):\n",
    "    \"\"\"Computes the NMAD, bias, outlier fraction for the regression tasks\n",
    "    x: ground-truth data\n",
    "    y: predicted data\n",
    "    \"\"\"\n",
    "    met = np.abs(pd.Series(y-x))\n",
    "    f_out = met/(1+x.astype(np.float32))\n",
    "    nmad=1.48*np.median(f_out)\n",
    "    bias = np.median(f_out)\n",
    "    #y_outlier = pd.Series(np.where(f_out > 0.30, 'outlier', 'not outlier'))\n",
    "    r2 = sklearn.metrics.r2_score(x, y)\n",
    "    #print(\"Outliers: \\n\", y_outlier.value_counts())\n",
    "    #outlier_fraction = y_outlier.value_counts()['outlier'] / len(y_outlier)\n",
    "    #print(\"Outlier fraction: \\n\", outlier_fraction)\n",
    "    #print(\"\\n Bias: \\n\", bias)\n",
    "    #print(\"\\n NMAD score: \\n\", nmad)\n",
    "    #print('\\n R2 Test: \\n', r2)\n",
    "    return nmad, bias, r2\n",
    "\n",
    "\n",
    "metrics = {'n_estimators': [], 'max_depth': [], 'NMAD': [], 'bias': [], 'r2': []}\n",
    "metrics = pd.DataFrame(data=metrics)\n",
    "for i in [50, 100, 150]:\n",
    "    for j in [0, 4, 7, 9]:\n",
    "        metrics['n_estimators']\n",
    "        model = catboost.CatBoostRegressor(n_estimators = i, max_depth = j, verbose = 0)\n",
    "        model.fit(x_train, y_train) # sample_weight = x_err_train\n",
    "        pred_z = model.predict(x_val)\n",
    "        # Tests for metric tuning:\n",
    "        nmad, bias, r2 = metric_scores_rgr(y_val, pred_z)\n",
    "        new_row = pd.DataFrame([[i, j, nmad, bias, r2]], columns=['n_estimators', 'max_depth', 'NMAD', 'bias', 'r2'])\n",
    "        metrics = pd.concat([metrics, new_row], axis = 0)\n",
    "        \n",
    "print(metrics)\n",
    "\n",
    "total_time = (time.time() - start)\n",
    "print(f'Total needed time for catboost: {total_time/60} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bdc495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:\n",
    "\n",
    "model = catboost.CatBoostRegressor(n_estimators = 150, max_depth = 9, verbose = 0)\n",
    "model.fit(x_train, y_train) # sample_weight = x_err_train\n",
    "pred_z = model.predict(x_test)\n",
    "#Metrics:\n",
    "nmad, bias, r2 = metric_scores_rgr(y_test, pred_z)\n",
    "print(\"\\n Bias: \\n\", bias)\n",
    "print(\"\\n NMAD score: \\n\", nmad)\n",
    "print('\\n R2 Test: \\n', r2)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(y_test, pred_z)\n",
    "plt.title('Predicted vs. reference SFR for test dataset')\n",
    "plt.xlabel('data sfr lp_SFR_best')\n",
    "plt.ylabel('predicted SFR')\n",
    "x0, x1 = np.min(y_test), np.max(y_test)\n",
    "y0, y1 = np.min(y_test), np.max(y_test)\n",
    "#plt.plot([np.min(y_test)-0.3*(1+np.min(y_test)), np.max(y_test)-0.30*(np.max(y_test)+1)], [y0, y1], color = 'red', linewidth = 2, linestyle = 'dashed')\n",
    "#plt.plot([np.min(y_test)+0.3*(1+np.min(y_test)), np.max(y_test)+0.30*(np.max(y_test)+1)], [y0, y1], color = 'red', linewidth = 2, linestyle = 'dashed')\n",
    "plt.plot([x0, x1], [y0, y1], color = 'black', linewidth = 2)\n",
    "\n",
    "\n",
    "# Histogram:\n",
    "fig_hist = plt.figure(figsize=(7,5))\n",
    "plt.hist(pred_z, 20,facecolor='orange', edgecolor = 'black', alpha=0.5, label = 'predicted SFR')\n",
    "plt.hist(y_test, 20, facecolor='blue', edgecolor = 'black', alpha=0.5, label = 'catalog SFR')\n",
    "plt.xlabel('SFR')\n",
    "plt.legend()\n",
    "# Residuals:\n",
    "residuals = y_test - pred_z\n",
    "fig_res = plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_test, residuals, alpha = 0.5, edgecolor = 'black')\n",
    "plt.xlabel('catalog SFR')\n",
    "plt.ylabel('residuals (lp_SFR - pred_SFR)')\n",
    "x0, x1 = np.min(y_test), np.max(y_test)\n",
    "y0, y1 = 0, 0\n",
    "plt.plot([x0, x1], [y0, y1], color = 'black', linewidth = 2, linestyle = 'dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e497d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance:\n",
    "def plot_feature_importance(importance,names,model_type):\n",
    "    \"\"\"Plots feature importance\n",
    "    importance: features importance output from model\n",
    "    names: features names\n",
    "    model_type: name of the model used to compute features importance\n",
    "    \"\"\"\n",
    "\n",
    "    #Create arrays from feature importance and feature names\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    #Create a DataFrame using a Dictionary\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    #Sort the DataFrame in order decreasing feature importance\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False, inplace=True)\n",
    "\n",
    "    #Define size of bar plot\n",
    "    plt.figure(figsize=(20,20))\n",
    "    #Plot Searborn bar chart\n",
    "    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "    #Add chart labels\n",
    "    plt.title(model_type + ' Feature Importance')\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature Names')\n",
    "\n",
    "features_importances = model.feature_importances_ #replace model by your model\n",
    "names = np.array(['HSC_g_FLUX_APER3', 'HSC_r_FLUX_APER3', 'HSC_i_FLUX_APER3',\n",
    "                 'HSC_z_FLUX_APER3', 'HSC_y_FLUX_APER3', 'UVISTA_Y_FLUX_APER3',\n",
    "                 'UVISTA_J_FLUX_APER3', 'UVISTA_H_FLUX_APER3', 'UVISTA_Ks_FLUX_APER3',\n",
    "                 'SC_IB427_FLUX_APER3', 'SC_IB464_FLUX_APER3', 'SC_IA484_FLUX_APER3',\n",
    "                 'SC_IB505_FLUX_APER3', 'SC_IA527_FLUX_APER3', 'SC_IB574_FLUX_APER3', \n",
    "                 'SC_IA624_FLUX_APER3', 'SC_IA679_FLUX_APER3', 'SC_IB709_FLUX_APER3', \n",
    "                 'SC_IA738_FLUX_APER3', 'SC_IA767_FLUX_APER3', 'SC_IB827_FLUX_APER3', \n",
    "                 'SC_NB711_FLUX_APER3', 'SC_NB816_FLUX_APER3', 'UVISTA_NB118_FLUX_APER3', \n",
    "                 'SC_B_FLUX_APER3', 'SC_gp_FLUX_APER3', 'SC_V_FLUX_APER3', 'SC_rp_FLUX_APER3', \n",
    "                 'SC_ip_FLUX_APER3', 'SC_zp_FLUX_APER3', 'SC_zpp_FLUX_APER3', 'HSC_g_FLUXERR_APER3', 'HSC_r_FLUXERR_APER3', 'HSC_i_FLUXERR_APER3',\n",
    "                 'HSC_z_FLUXERR_APER3', 'HSC_y_FLUXERR_APER3', 'UVISTA_Y_FLUXERR_APER3',\n",
    "                 'UVISTA_J_FLUXERR_APER3', 'UVISTA_H_FLUXERR_APER3', 'UVISTA_Ks_FLUXERR_APER3',\n",
    "                 'SC_IB427_FLUXERR_APER3', 'SC_IB464_FLUXERR_APER3', 'SC_IA484_FLUXERR_APER3',\n",
    "                 'SC_IB505_FLUXERR_APER3', 'SC_IA527_FLUXERR_APER3', 'SC_IB574_FLUXERR_APER3', \n",
    "                 'SC_IA624_FLUXERR_APER3', 'SC_IA679_FLUXERR_APER3', 'SC_IB709_FLUXERR_APER3', \n",
    "                 'SC_IA738_FLUXERR_APER3', 'SC_IA767_FLUXERR_APER3', 'SC_IB827_FLUXERR_APER3', \n",
    "                 'SC_NB711_FLUXERR_APER3', 'SC_NB816_FLUXERR_APER3', 'UVISTA_NB118_FLUXERR_APER3', \n",
    "                 'SC_B_FLUXERR_APER3', 'SC_gp_FLUXERR_APER3', 'SC_V_FLUXERR_APER3', 'SC_rp_FLUXERR_APER3', \n",
    "                 'SC_ip_FLUXERR_APER3', 'SC_zp_FLUXERR_APER3', 'SC_zpp_FLUXERR_APER3'])#list of the columns from the X_train data set\n",
    "model_type = 'CatBoost' # change according to the model to be used. Only used in the plots.\n",
    "\n",
    "plot_feature_importance(features_importances,names,model_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
